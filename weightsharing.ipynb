{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "from torch.nn import functional as F\n",
    "import dlc_practical_prologue as prologue\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from torch import optim\n",
    "from torch import Tensor\n",
    "from torch import nn\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(device)\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating pairs of 14x14\n",
    "N=1000\n",
    "(train_input,train_target,train_classes, \\\n",
    " test_input,test_target,test_classes) = prologue.generate_pair_sets(N)\n",
    "\n",
    "train_input = train_input.to(device)\n",
    "test_input = test_input.to(device)\n",
    "train_target = train_target.to(device)\n",
    "test_target = test_target.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "def norm_(train_input,test_input):\n",
    "    \"\"\"Function to normalize the input\"\"\"\n",
    "    mu, std = train_input.mean(), train_input.std()\n",
    "    train_inputOut = train_input.sub_(mu).div_(std)\n",
    "    test_inputOut = test_input.sub_(mu).div_(std)\n",
    "    return train_inputOut, test_inputOut\n",
    "train_input,test_input = norm_(train_input,test_input);\n",
    "print(train_input.device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trainmodel and runnets are here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_input, train_target, nb_epochs=50, \n",
    "                eta=9e-2, mini_batch_size=50,printTrain = False, graphLoss = False):\n",
    "    \"\"\"Trains the model, using CrossEntropyLoss and SGD \n",
    "    Model : Architecture to be tested, pytorch.nn.Module\n",
    "    Train_input : Input tensors Nx2x14x14, N = 1000\n",
    "    Train_target : Target labels, N, classes = 0 or 1\n",
    "    Nb_epochs : nb of epochs to train over\n",
    "    eta : Learning rate\n",
    "    mini_batch_size : Size of minibatch to be processed\"\"\"\n",
    "    model.train(True)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model.to(device)\n",
    "    criterion.to(device)\n",
    "    optimizer = optim.SGD(model.parameters(),lr=eta)\n",
    "    losses = []\n",
    "    \n",
    "    for e in range(nb_epochs):\n",
    "        for b in range(0, train_input.size(0), mini_batch_size):    \n",
    "            output = model(train_input.narrow(0, b, mini_batch_size))\n",
    "            loss = criterion(output, train_target.narrow(0, b, mini_batch_size))\n",
    "            losses.append(loss)\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        if printTrain : \n",
    "            print(\"Epoch : {} :: Train error : {}/{}, {:0f}%\".format(e,\n",
    "            compute_nb_errors(model,train_input,train_target,mini_batch_size),train_target.size(0),\n",
    "            (100*compute_nb_errors(model,train_input,train_target,mini_batch_size)/train_target.size(0))))\n",
    "    if graphLoss : \n",
    "        plt.plot(losses)\n",
    "        plt.ylabel('loss')\n",
    "#--------------------------------------------------------------------------------------------------------#\n",
    "def compute_nb_errors(model,data_input,data_target,mini_batch_size):\n",
    "    \"\"\"std from the sÃ©ries\"\"\"\n",
    "    nb_errors = 0;\n",
    "    model.to(device)\n",
    "    data_input, data_target = data_input.to(device),data_target.to(device)\n",
    "    for b in range(0,data_input.size(0),mini_batch_size):\n",
    "        output = model(data_input.narrow(0,b,mini_batch_size))\n",
    "        _, predicted_classes = torch.max(output, 1)\n",
    "        for k in range(mini_batch_size):\n",
    "            if data_target[b+k]!=predicted_classes[k]:\n",
    "                nb_errors += 1\n",
    "    \n",
    "    return nb_errors\n",
    "#--------------------------------------------------------------------------------------------------------#\n",
    "def run_net(model,train_input,train_target,\n",
    "            test_input, test_target,\n",
    "            nb_epochs = 50,eta=9e-2,mini_batch_size=50,\n",
    "            printTrain = False,graphLoss = False):\n",
    "    \"\"\"\"\"\"\n",
    "    model.to(device)\n",
    "    print(\"Model tested : {}\".format(str(model)[:str(model).find('(')]))\n",
    "    print(\"\"\"Using {} epochs, lr = {:.04f},Mini batch size = {}\"\"\".format(nb_epochs,\n",
    "                                                                          eta,mini_batch_size))\n",
    "    train_model(model, train_input, train_target,\n",
    "                nb_epochs, eta, mini_batch_size,printTrain,graphLoss)\n",
    "    model.train(False)\n",
    "    train_error = compute_nb_errors(model, train_input, train_target,mini_batch_size) / train_input.size(0) * 100\n",
    "    test_error = compute_nb_errors(model, test_input, test_target,mini_batch_size) / test_input.size(0) * 100\n",
    "    print('train_error {:.02f}% test_error {:.02f}% \\n'.format(\n",
    "                train_error,\n",
    "                test_error\n",
    "            )\n",
    "        )\n",
    "    return float(test_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weight sharing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Conv layers, based on the filter size and layer sizes tested in explorationLeNetDual\n",
    "# must take 1x14x14 (so the same layers is used on both images)\n",
    "# Separated the modules because I couldn't figure out how to make a single net work...\n",
    "# will maybe merge into a single net later.\n",
    "class convlayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(convlayer, self).__init__()\n",
    "        #self.conv1 : takes 1x14x14, gives 32x12x12, then maxpool(k=2) -> 32x6x6\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3) \n",
    "        #self.conv2 : takes 32x6x6, gives 64x4x4, then maxpool(k=2) -> outputs 64x2x2 to the fc layers\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), kernel_size=2,stride=2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), kernel_size=2,stride=2))\n",
    "        return x\n",
    "#fc layers, adding a supp layer that has output dim 10 (instead of 2)\n",
    "#in order to maybe calculate an aux loss on this output to have classification?\n",
    "class shared_fclayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(shared_fclayer,self).__init__()\n",
    "        #gets in 64x2x2, convers to 1x250\n",
    "        self.fc1 = nn.Linear(2*2*64,250)\n",
    "        self.bn1 = nn.BatchNorm1d(250)\n",
    "        #second layer : 250 to 100\n",
    "        self.fc2 = nn.Linear(250,100)  \n",
    "        self.bn2 = nn.BatchNorm1d(100)\n",
    "        #outputs dim 10 so we can test the aux loss for classifying numbers\n",
    "        #use softmax on fc3?\n",
    "        self.fc3 = nn.Linear(100,10)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "    def forward(self,x):\n",
    "        x = self.dropout(self.bn1(F.relu(self.fc1(x.view(-1,2*2*64)))))\n",
    "        x = self.dropout(self.bn2(F.relu(self.fc2(x))))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        return x\n",
    "#extra final layer, not shared\n",
    "class final_predictionlayer(nn.Module):\n",
    "    #this final layer should take 2*10 (one for each image) and output 2 \n",
    "    def __init__(self):\n",
    "        super(final_predictionlayer,self).__init__()\n",
    "        self.final = nn.Linear(20,2)\n",
    "    def forward(self,x):\n",
    "        x = self.final(x)\n",
    "        return x\n",
    "    \n",
    "class total_net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(total_net,self).__init__()\n",
    "        self.convlayer = convlayer()\n",
    "        self.fclayer = shared_fclayer()\n",
    "        self.final = final_predictionlayer()\n",
    "    def forward(self,x):\n",
    "        tmp1 = x.narrow(1,0,1) #viewing only one image\n",
    "        tmp2 = x.narrow(1,1,1) #viewing only one image\n",
    "        #applying the conv layers\n",
    "        tmp1 = self.convlayer.forward(tmp1) \n",
    "        tmp2 = self.convlayer.forward(tmp2)\n",
    "        #applying the fc layers\n",
    "        tmp1 = self.fclayer(tmp1)\n",
    "        tmp2 = self.fclayer(tmp2)\n",
    "        #viewing and final prediction\n",
    "        output = torch.cat((tmp1,tmp2),1)\n",
    "        output.view(-1,20)\n",
    "        x = F.softmax(self.final(output),dim=1)\n",
    "        return x\n",
    "               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`def run_net(model,train_input,train_target,\n",
    "            test_input, test_target,\n",
    "            nb_epochs = 50,eta=9e-2,mini_batch_size=50,\n",
    "            printTrain = False,graphLoss = False):`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 25 epochs, lr = 0.1000,Mini batch size = 25\n",
      "Epoch : 0 :: Train error : 220/1000, 21.500000%\n",
      "Epoch : 1 :: Train error : 169/1000, 17.600000%\n",
      "Epoch : 2 :: Train error : 139/1000, 14.500000%\n",
      "Epoch : 3 :: Train error : 109/1000, 11.700000%\n",
      "Epoch : 4 :: Train error : 103/1000, 9.000000%\n",
      "Epoch : 5 :: Train error : 134/1000, 12.900000%\n",
      "Epoch : 6 :: Train error : 89/1000, 9.000000%\n",
      "Epoch : 7 :: Train error : 84/1000, 8.400000%\n",
      "Epoch : 8 :: Train error : 55/1000, 6.400000%\n",
      "Epoch : 9 :: Train error : 57/1000, 5.200000%\n",
      "Epoch : 10 :: Train error : 59/1000, 4.700000%\n",
      "Epoch : 11 :: Train error : 42/1000, 3.800000%\n",
      "Epoch : 12 :: Train error : 69/1000, 6.600000%\n",
      "Epoch : 13 :: Train error : 35/1000, 3.000000%\n",
      "Epoch : 14 :: Train error : 24/1000, 2.700000%\n",
      "Epoch : 15 :: Train error : 51/1000, 4.300000%\n",
      "Epoch : 16 :: Train error : 34/1000, 3.600000%\n",
      "Epoch : 17 :: Train error : 16/1000, 1.700000%\n",
      "Epoch : 18 :: Train error : 16/1000, 1.600000%\n",
      "Epoch : 19 :: Train error : 14/1000, 1.400000%\n",
      "Epoch : 20 :: Train error : 19/1000, 1.500000%\n",
      "Epoch : 21 :: Train error : 22/1000, 1.700000%\n",
      "Epoch : 22 :: Train error : 19/1000, 2.200000%\n",
      "Epoch : 23 :: Train error : 20/1000, 1.700000%\n",
      "Epoch : 24 :: Train error : 11/1000, 1.100000%\n",
      "train_error 1.10% test_error 11.20% \n",
      "\n",
      "Using 25 epochs, lr = 0.1000,Mini batch size = 25\n",
      "Epoch : 0 :: Train error : 193/1000, 21.300000%\n",
      "Epoch : 1 :: Train error : 180/1000, 17.600000%\n",
      "Epoch : 2 :: Train error : 139/1000, 13.800000%\n",
      "Epoch : 3 :: Train error : 105/1000, 10.100000%\n",
      "Epoch : 4 :: Train error : 79/1000, 8.600000%\n",
      "Epoch : 5 :: Train error : 76/1000, 7.700000%\n",
      "Epoch : 6 :: Train error : 68/1000, 6.600000%\n",
      "Epoch : 7 :: Train error : 56/1000, 6.400000%\n",
      "Epoch : 8 :: Train error : 43/1000, 4.900000%\n",
      "Epoch : 9 :: Train error : 36/1000, 4.300000%\n",
      "Epoch : 10 :: Train error : 30/1000, 3.200000%\n",
      "Epoch : 11 :: Train error : 29/1000, 3.100000%\n",
      "Epoch : 12 :: Train error : 66/1000, 5.400000%\n",
      "Epoch : 13 :: Train error : 23/1000, 2.000000%\n",
      "Epoch : 14 :: Train error : 12/1000, 1.200000%\n",
      "Epoch : 15 :: Train error : 11/1000, 1.000000%\n",
      "Epoch : 16 :: Train error : 26/1000, 3.100000%\n",
      "Epoch : 17 :: Train error : 16/1000, 1.300000%\n",
      "Epoch : 18 :: Train error : 23/1000, 2.300000%\n",
      "Epoch : 19 :: Train error : 8/1000, 1.100000%\n",
      "Epoch : 20 :: Train error : 10/1000, 0.900000%\n",
      "Epoch : 21 :: Train error : 8/1000, 0.600000%\n",
      "Epoch : 22 :: Train error : 5/1000, 0.500000%\n",
      "Epoch : 23 :: Train error : 15/1000, 1.800000%\n",
      "Epoch : 24 :: Train error : 5/1000, 0.300000%\n",
      "train_error 0.80% test_error 13.10% \n",
      "\n",
      "Using 25 epochs, lr = 0.1000,Mini batch size = 25\n",
      "Epoch : 0 :: Train error : 180/1000, 18.300000%\n",
      "Epoch : 1 :: Train error : 181/1000, 17.200000%\n",
      "Epoch : 2 :: Train error : 131/1000, 13.400000%\n",
      "Epoch : 3 :: Train error : 115/1000, 11.100000%\n",
      "Epoch : 4 :: Train error : 90/1000, 10.200000%\n",
      "Epoch : 5 :: Train error : 90/1000, 9.000000%\n",
      "Epoch : 6 :: Train error : 78/1000, 9.300000%\n",
      "Epoch : 7 :: Train error : 74/1000, 6.900000%\n",
      "Epoch : 8 :: Train error : 58/1000, 5.500000%\n",
      "Epoch : 9 :: Train error : 52/1000, 5.500000%\n",
      "Epoch : 10 :: Train error : 62/1000, 5.500000%\n",
      "Epoch : 11 :: Train error : 45/1000, 4.400000%\n",
      "Epoch : 12 :: Train error : 32/1000, 3.500000%\n",
      "Epoch : 13 :: Train error : 38/1000, 3.200000%\n",
      "Epoch : 14 :: Train error : 39/1000, 3.600000%\n",
      "Epoch : 15 :: Train error : 40/1000, 4.500000%\n",
      "Epoch : 16 :: Train error : 35/1000, 4.100000%\n",
      "Epoch : 17 :: Train error : 32/1000, 3.600000%\n",
      "Epoch : 18 :: Train error : 26/1000, 2.500000%\n",
      "Epoch : 19 :: Train error : 28/1000, 2.300000%\n",
      "Epoch : 20 :: Train error : 19/1000, 1.600000%\n",
      "Epoch : 21 :: Train error : 18/1000, 1.700000%\n",
      "Epoch : 22 :: Train error : 15/1000, 1.600000%\n",
      "Epoch : 23 :: Train error : 16/1000, 1.100000%\n",
      "Epoch : 24 :: Train error : 12/1000, 1.400000%\n",
      "train_error 1.70% test_error 14.30% \n",
      "\n",
      "Using 25 epochs, lr = 0.1000,Mini batch size = 25\n",
      "Epoch : 0 :: Train error : 236/1000, 23.600000%\n",
      "Epoch : 1 :: Train error : 186/1000, 19.600000%\n",
      "Epoch : 2 :: Train error : 171/1000, 17.300000%\n",
      "Epoch : 3 :: Train error : 144/1000, 14.800000%\n",
      "Epoch : 4 :: Train error : 154/1000, 14.000000%\n",
      "Epoch : 5 :: Train error : 119/1000, 12.700000%\n",
      "Epoch : 6 :: Train error : 86/1000, 9.800000%\n",
      "Epoch : 7 :: Train error : 84/1000, 8.400000%\n",
      "Epoch : 8 :: Train error : 59/1000, 6.300000%\n",
      "Epoch : 9 :: Train error : 58/1000, 5.800000%\n",
      "Epoch : 10 :: Train error : 75/1000, 7.400000%\n",
      "Epoch : 11 :: Train error : 61/1000, 5.800000%\n",
      "Epoch : 12 :: Train error : 55/1000, 5.000000%\n",
      "Epoch : 13 :: Train error : 48/1000, 4.600000%\n",
      "Epoch : 14 :: Train error : 40/1000, 3.800000%\n",
      "Epoch : 15 :: Train error : 53/1000, 5.300000%\n",
      "Epoch : 16 :: Train error : 41/1000, 4.200000%\n",
      "Epoch : 17 :: Train error : 40/1000, 3.100000%\n",
      "Epoch : 18 :: Train error : 37/1000, 3.900000%\n",
      "Epoch : 19 :: Train error : 27/1000, 3.500000%\n",
      "Epoch : 20 :: Train error : 19/1000, 1.600000%\n",
      "Epoch : 21 :: Train error : 14/1000, 1.600000%\n",
      "Epoch : 22 :: Train error : 20/1000, 2.000000%\n",
      "Epoch : 23 :: Train error : 16/1000, 2.000000%\n",
      "Epoch : 24 :: Train error : 16/1000, 1.700000%\n",
      "train_error 1.60% test_error 14.00% \n",
      "\n",
      "Using 25 epochs, lr = 0.1000,Mini batch size = 25\n",
      "Epoch : 0 :: Train error : 229/1000, 21.300000%\n",
      "Epoch : 1 :: Train error : 176/1000, 15.900000%\n",
      "Epoch : 2 :: Train error : 149/1000, 15.000000%\n",
      "Epoch : 3 :: Train error : 129/1000, 12.300000%\n",
      "Epoch : 4 :: Train error : 100/1000, 8.500000%\n",
      "Epoch : 5 :: Train error : 92/1000, 8.700000%\n",
      "Epoch : 6 :: Train error : 66/1000, 6.000000%\n",
      "Epoch : 7 :: Train error : 55/1000, 5.900000%\n",
      "Epoch : 8 :: Train error : 64/1000, 6.400000%\n",
      "Epoch : 9 :: Train error : 36/1000, 3.800000%\n",
      "Epoch : 10 :: Train error : 33/1000, 3.900000%\n",
      "Epoch : 11 :: Train error : 32/1000, 3.400000%\n",
      "Epoch : 12 :: Train error : 31/1000, 2.900000%\n",
      "Epoch : 13 :: Train error : 29/1000, 2.600000%\n",
      "Epoch : 14 :: Train error : 20/1000, 2.300000%\n",
      "Epoch : 15 :: Train error : 27/1000, 2.900000%\n",
      "Epoch : 16 :: Train error : 21/1000, 1.900000%\n",
      "Epoch : 17 :: Train error : 21/1000, 2.000000%\n",
      "Epoch : 18 :: Train error : 17/1000, 2.500000%\n",
      "Epoch : 19 :: Train error : 16/1000, 1.600000%\n",
      "Epoch : 20 :: Train error : 20/1000, 1.600000%\n",
      "Epoch : 21 :: Train error : 13/1000, 1.300000%\n",
      "Epoch : 22 :: Train error : 10/1000, 1.100000%\n",
      "Epoch : 23 :: Train error : 12/1000, 1.700000%\n",
      "Epoch : 24 :: Train error : 12/1000, 1.700000%\n",
      "train_error 1.20% test_error 14.30% \n",
      "\n",
      "13.38\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "err = 0;\n",
    "for n in range(5):\n",
    "    err+= run_net(total_net(),train_input,train_target,\n",
    "                 test_input,test_target,nb_epochs = 25, \n",
    "                  eta = 1e-1,mini_batch_size=25,printTrain=True,graphLoss=True)\n",
    "    \n",
    "print(err/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 25 epochs, lr = 0.1000,Mini batch size = 25\n",
      "train_error 1.50% test_error 12.40% \n",
      "\n",
      "Using 25 epochs, lr = 0.1000,Mini batch size = 25\n",
      "train_error 0.80% test_error 13.80% \n",
      "\n",
      "Using 25 epochs, lr = 0.1000,Mini batch size = 25\n",
      "train_error 1.60% test_error 13.00% \n",
      "\n",
      "Using 25 epochs, lr = 0.1000,Mini batch size = 50\n",
      "train_error 0.50% test_error 14.40% \n",
      "\n",
      "Using 25 epochs, lr = 0.1000,Mini batch size = 50\n",
      "train_error 1.00% test_error 16.50% \n",
      "\n",
      "Using 25 epochs, lr = 0.1000,Mini batch size = 50\n",
      "train_error 0.40% test_error 15.30% \n",
      "\n",
      "Using 25 epochs, lr = 0.1000,Mini batch size = 100\n",
      "train_error 0.70% test_error 13.50% \n",
      "\n",
      "Using 25 epochs, lr = 0.1000,Mini batch size = 100\n",
      "train_error 0.50% test_error 14.70% \n",
      "\n",
      "Using 25 epochs, lr = 0.1000,Mini batch size = 100\n",
      "train_error 1.20% test_error 11.70% \n",
      "\n",
      "Using 25 epochs, lr = 0.0750,Mini batch size = 25\n",
      "train_error 1.10% test_error 12.00% \n",
      "\n",
      "Using 25 epochs, lr = 0.0750,Mini batch size = 25\n",
      "train_error 0.90% test_error 14.50% \n",
      "\n",
      "Using 25 epochs, lr = 0.0750,Mini batch size = 25\n",
      "train_error 1.10% test_error 15.10% \n",
      "\n",
      "Using 25 epochs, lr = 0.0750,Mini batch size = 50\n",
      "train_error 0.20% test_error 14.10% \n",
      "\n",
      "Using 25 epochs, lr = 0.0750,Mini batch size = 50\n",
      "train_error 0.40% test_error 15.00% \n",
      "\n",
      "Using 25 epochs, lr = 0.0750,Mini batch size = 50\n",
      "train_error 0.50% test_error 15.00% \n",
      "\n",
      "Using 25 epochs, lr = 0.0750,Mini batch size = 100\n",
      "train_error 2.30% test_error 13.30% \n",
      "\n",
      "Using 25 epochs, lr = 0.0750,Mini batch size = 100\n",
      "train_error 0.80% test_error 15.60% \n",
      "\n",
      "Using 25 epochs, lr = 0.0750,Mini batch size = 100\n",
      "train_error 0.40% test_error 15.20% \n",
      "\n",
      "Using 25 epochs, lr = 0.0500,Mini batch size = 25\n",
      "train_error 0.80% test_error 15.30% \n",
      "\n",
      "Using 25 epochs, lr = 0.0500,Mini batch size = 25\n",
      "train_error 1.00% test_error 13.90% \n",
      "\n",
      "Using 25 epochs, lr = 0.0500,Mini batch size = 25\n",
      "train_error 0.50% test_error 13.80% \n",
      "\n",
      "Using 25 epochs, lr = 0.0500,Mini batch size = 50\n",
      "train_error 0.10% test_error 16.30% \n",
      "\n",
      "Using 25 epochs, lr = 0.0500,Mini batch size = 50\n",
      "train_error 0.30% test_error 13.90% \n",
      "\n",
      "Using 25 epochs, lr = 0.0500,Mini batch size = 50\n",
      "train_error 0.60% test_error 15.10% \n",
      "\n",
      "Using 25 epochs, lr = 0.0500,Mini batch size = 100\n",
      "train_error 0.90% test_error 12.50% \n",
      "\n",
      "Using 25 epochs, lr = 0.0500,Mini batch size = 100\n",
      "train_error 0.80% test_error 14.10% \n",
      "\n",
      "Using 25 epochs, lr = 0.0500,Mini batch size = 100\n",
      "train_error 2.50% test_error 14.20% \n",
      "\n",
      "Using 25 epochs, lr = 0.0330,Mini batch size = 25\n",
      "train_error 0.50% test_error 14.50% \n",
      "\n",
      "Using 25 epochs, lr = 0.0330,Mini batch size = 25\n",
      "train_error 0.40% test_error 15.50% \n",
      "\n",
      "Using 25 epochs, lr = 0.0330,Mini batch size = 25\n",
      "train_error 1.30% test_error 14.80% \n",
      "\n",
      "Using 25 epochs, lr = 0.0330,Mini batch size = 50\n",
      "train_error 0.60% test_error 16.50% \n",
      "\n",
      "Using 25 epochs, lr = 0.0330,Mini batch size = 50\n",
      "train_error 1.00% test_error 13.20% \n",
      "\n",
      "Using 25 epochs, lr = 0.0330,Mini batch size = 50\n",
      "train_error 1.10% test_error 16.30% \n",
      "\n",
      "Using 25 epochs, lr = 0.0330,Mini batch size = 100\n",
      "train_error 5.60% test_error 15.00% \n",
      "\n",
      "Using 25 epochs, lr = 0.0330,Mini batch size = 100\n",
      "train_error 3.60% test_error 13.40% \n",
      "\n",
      "Using 25 epochs, lr = 0.0330,Mini batch size = 100\n",
      "train_error 2.80% test_error 13.00% \n",
      "\n",
      "Using 37 epochs, lr = 0.1000,Mini batch size = 25\n",
      "train_error 1.20% test_error 11.40% \n",
      "\n",
      "Using 37 epochs, lr = 0.1000,Mini batch size = 25\n",
      "train_error 0.80% test_error 13.00% \n",
      "\n",
      "Using 37 epochs, lr = 0.1000,Mini batch size = 25\n",
      "train_error 1.10% test_error 13.80% \n",
      "\n",
      "Using 37 epochs, lr = 0.1000,Mini batch size = 50\n",
      "train_error 0.30% test_error 14.30% \n",
      "\n",
      "Using 37 epochs, lr = 0.1000,Mini batch size = 50\n",
      "train_error 0.30% test_error 14.60% \n",
      "\n",
      "Using 37 epochs, lr = 0.1000,Mini batch size = 50\n",
      "train_error 0.50% test_error 15.10% \n",
      "\n",
      "Using 37 epochs, lr = 0.1000,Mini batch size = 100\n",
      "train_error 0.10% test_error 14.60% \n",
      "\n",
      "Using 37 epochs, lr = 0.1000,Mini batch size = 100\n",
      "train_error 0.20% test_error 15.40% \n",
      "\n",
      "Using 37 epochs, lr = 0.1000,Mini batch size = 100\n",
      "train_error 0.20% test_error 14.50% \n",
      "\n",
      "Using 37 epochs, lr = 0.0750,Mini batch size = 25\n",
      "train_error 1.30% test_error 12.70% \n",
      "\n",
      "Using 37 epochs, lr = 0.0750,Mini batch size = 25\n",
      "train_error 1.10% test_error 14.40% \n",
      "\n",
      "Using 37 epochs, lr = 0.0750,Mini batch size = 25\n",
      "train_error 1.00% test_error 13.00% \n",
      "\n",
      "Using 37 epochs, lr = 0.0750,Mini batch size = 50\n",
      "train_error 0.40% test_error 14.20% \n",
      "\n",
      "Using 37 epochs, lr = 0.0750,Mini batch size = 50\n",
      "train_error 0.70% test_error 14.30% \n",
      "\n",
      "Using 37 epochs, lr = 0.0750,Mini batch size = 50\n",
      "train_error 0.20% test_error 14.10% \n",
      "\n",
      "Using 37 epochs, lr = 0.0750,Mini batch size = 100\n",
      "train_error 0.20% test_error 16.60% \n",
      "\n",
      "Using 37 epochs, lr = 0.0750,Mini batch size = 100\n",
      "train_error 0.50% test_error 17.30% \n",
      "\n",
      "Using 37 epochs, lr = 0.0750,Mini batch size = 100\n",
      "train_error 0.20% test_error 15.50% \n",
      "\n",
      "Using 37 epochs, lr = 0.0500,Mini batch size = 25\n",
      "train_error 2.20% test_error 15.20% \n",
      "\n",
      "Using 37 epochs, lr = 0.0500,Mini batch size = 25\n",
      "train_error 1.00% test_error 14.10% \n",
      "\n",
      "Using 37 epochs, lr = 0.0500,Mini batch size = 25\n",
      "train_error 0.70% test_error 13.10% \n",
      "\n",
      "Using 37 epochs, lr = 0.0500,Mini batch size = 50\n",
      "train_error 0.20% test_error 17.10% \n",
      "\n",
      "Using 37 epochs, lr = 0.0500,Mini batch size = 50\n",
      "train_error 0.20% test_error 14.70% \n",
      "\n",
      "Using 37 epochs, lr = 0.0500,Mini batch size = 50\n",
      "train_error 0.50% test_error 15.30% \n",
      "\n",
      "Using 37 epochs, lr = 0.0500,Mini batch size = 100\n",
      "train_error 0.40% test_error 15.10% \n",
      "\n",
      "Using 37 epochs, lr = 0.0500,Mini batch size = 100\n",
      "train_error 0.30% test_error 16.50% \n",
      "\n",
      "Using 37 epochs, lr = 0.0500,Mini batch size = 100\n",
      "train_error 0.20% test_error 14.20% \n",
      "\n",
      "Using 37 epochs, lr = 0.0330,Mini batch size = 25\n",
      "train_error 0.30% test_error 13.50% \n",
      "\n",
      "Using 37 epochs, lr = 0.0330,Mini batch size = 25\n",
      "train_error 0.60% test_error 13.50% \n",
      "\n",
      "Using 37 epochs, lr = 0.0330,Mini batch size = 25\n",
      "train_error 0.60% test_error 14.20% \n",
      "\n",
      "Using 37 epochs, lr = 0.0330,Mini batch size = 50\n",
      "train_error 0.30% test_error 15.40% \n",
      "\n",
      "Using 37 epochs, lr = 0.0330,Mini batch size = 50\n",
      "train_error 0.30% test_error 14.70% \n",
      "\n",
      "Using 37 epochs, lr = 0.0330,Mini batch size = 50\n",
      "train_error 0.50% test_error 14.90% \n",
      "\n",
      "Using 37 epochs, lr = 0.0330,Mini batch size = 100\n",
      "train_error 0.50% test_error 14.30% \n",
      "\n",
      "Using 37 epochs, lr = 0.0330,Mini batch size = 100\n",
      "train_error 1.80% test_error 15.60% \n",
      "\n",
      "Using 37 epochs, lr = 0.0330,Mini batch size = 100\n",
      "train_error 0.60% test_error 14.40% \n",
      "\n",
      "Using 50 epochs, lr = 0.1000,Mini batch size = 25\n",
      "train_error 0.90% test_error 12.30% \n",
      "\n",
      "Using 50 epochs, lr = 0.1000,Mini batch size = 25\n",
      "train_error 0.60% test_error 11.90% \n",
      "\n",
      "Using 50 epochs, lr = 0.1000,Mini batch size = 25\n",
      "train_error 0.60% test_error 12.50% \n",
      "\n",
      "Using 50 epochs, lr = 0.1000,Mini batch size = 50\n",
      "train_error 0.40% test_error 12.90% \n",
      "\n",
      "Using 50 epochs, lr = 0.1000,Mini batch size = 50\n",
      "train_error 0.20% test_error 13.40% \n",
      "\n",
      "Using 50 epochs, lr = 0.1000,Mini batch size = 50\n",
      "train_error 0.30% test_error 14.10% \n",
      "\n",
      "Using 50 epochs, lr = 0.1000,Mini batch size = 100\n",
      "train_error 0.30% test_error 15.50% \n",
      "\n",
      "Using 50 epochs, lr = 0.1000,Mini batch size = 100\n",
      "train_error 0.20% test_error 14.00% \n",
      "\n",
      "Using 50 epochs, lr = 0.1000,Mini batch size = 100\n",
      "train_error 0.20% test_error 15.10% \n",
      "\n",
      "Using 50 epochs, lr = 0.0750,Mini batch size = 25\n",
      "train_error 0.70% test_error 14.30% \n",
      "\n",
      "Using 50 epochs, lr = 0.0750,Mini batch size = 25\n",
      "train_error 0.70% test_error 12.70% \n",
      "\n",
      "Using 50 epochs, lr = 0.0750,Mini batch size = 25\n",
      "train_error 0.60% test_error 15.60% \n",
      "\n",
      "Using 50 epochs, lr = 0.0750,Mini batch size = 50\n",
      "train_error 0.40% test_error 15.60% \n",
      "\n",
      "Using 50 epochs, lr = 0.0750,Mini batch size = 50\n",
      "train_error 0.10% test_error 14.20% \n",
      "\n",
      "Using 50 epochs, lr = 0.0750,Mini batch size = 50\n",
      "train_error 0.20% test_error 14.50% \n",
      "\n",
      "Using 50 epochs, lr = 0.0750,Mini batch size = 100\n",
      "train_error 0.00% test_error 13.80% \n",
      "\n",
      "Using 50 epochs, lr = 0.0750,Mini batch size = 100\n",
      "train_error 0.10% test_error 13.10% \n",
      "\n",
      "Using 50 epochs, lr = 0.0750,Mini batch size = 100\n",
      "train_error 0.10% test_error 15.70% \n",
      "\n",
      "Using 50 epochs, lr = 0.0500,Mini batch size = 25\n",
      "train_error 0.90% test_error 12.30% \n",
      "\n",
      "Using 50 epochs, lr = 0.0500,Mini batch size = 25\n",
      "train_error 0.40% test_error 13.20% \n",
      "\n",
      "Using 50 epochs, lr = 0.0500,Mini batch size = 25\n",
      "train_error 0.50% test_error 13.10% \n",
      "\n",
      "Using 50 epochs, lr = 0.0500,Mini batch size = 50\n",
      "train_error 0.30% test_error 15.20% \n",
      "\n",
      "Using 50 epochs, lr = 0.0500,Mini batch size = 50\n",
      "train_error 0.20% test_error 16.40% \n",
      "\n",
      "Using 50 epochs, lr = 0.0500,Mini batch size = 50\n",
      "train_error 0.20% test_error 17.10% \n",
      "\n",
      "Using 50 epochs, lr = 0.0500,Mini batch size = 100\n",
      "train_error 0.20% test_error 14.80% \n",
      "\n",
      "Using 50 epochs, lr = 0.0500,Mini batch size = 100\n",
      "train_error 0.10% test_error 14.60% \n",
      "\n",
      "Using 50 epochs, lr = 0.0500,Mini batch size = 100\n",
      "train_error 0.20% test_error 16.70% \n",
      "\n",
      "Using 50 epochs, lr = 0.0330,Mini batch size = 25\n",
      "train_error 0.40% test_error 14.40% \n",
      "\n",
      "Using 50 epochs, lr = 0.0330,Mini batch size = 25\n",
      "train_error 0.50% test_error 14.80% \n",
      "\n",
      "Using 50 epochs, lr = 0.0330,Mini batch size = 25\n",
      "train_error 0.50% test_error 14.00% \n",
      "\n",
      "Using 50 epochs, lr = 0.0330,Mini batch size = 50\n",
      "train_error 0.10% test_error 13.40% \n",
      "\n",
      "Using 50 epochs, lr = 0.0330,Mini batch size = 50\n",
      "train_error 0.10% test_error 13.20% \n",
      "\n",
      "Using 50 epochs, lr = 0.0330,Mini batch size = 50\n",
      "train_error 0.20% test_error 15.70% \n",
      "\n",
      "Using 50 epochs, lr = 0.0330,Mini batch size = 100\n",
      "train_error 0.10% test_error 13.60% \n",
      "\n",
      "Using 50 epochs, lr = 0.0330,Mini batch size = 100\n",
      "train_error 0.30% test_error 15.90% \n",
      "\n",
      "Using 50 epochs, lr = 0.0330,Mini batch size = 100\n",
      "train_error 1.10% test_error 16.10% \n",
      "\n",
      "[[13.066666666666668, 25, 0.1, 25], [13.299999999999999, 25, 0.1, 100], [13.866666666666667, 25, 0.075, 25], [13.6, 25, 0.05, 100], [13.799999999999999, 25, 0.033, 100], [12.733333333333334, 37, 0.1, 25], [13.366666666666665, 37, 0.075, 25], [13.733333333333334, 37, 0.033, 25], [12.233333333333334, 50, 0.1, 25], [13.466666666666667, 50, 0.1, 50], [12.866666666666667, 50, 0.05, 25]]\n"
     ]
    }
   ],
   "source": [
    "goodList = []\n",
    "for e in [25,37,50]:\n",
    "    for lr in [1e-1,7.5e-2,5e-2,3.3e-2]:\n",
    "        for bn in [25,50,100]:\n",
    "            err = 0.;\n",
    "            for n in range(3):\n",
    "                model = total_net()\n",
    "                err+=run_net(model,train_input,train_target,\n",
    "                             test_input,test_target,e,lr,bn)\n",
    "            if err/3 <= 14:\n",
    "                goodList.append([err/3,e,lr,bn])\n",
    "print(goodList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### testing various layer sizes and dropouts\n",
    "`total_net_test(l1,l2,drop)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#big brain LOOPS\n",
    "class shared_fclayer_test(nn.Module):\n",
    "    def __init__(self,l1,l2,drop):\n",
    "        super(shared_fclayer_test,self).__init__()\n",
    "        #gets in 64x2x2, convers to 1x250\n",
    "        self.fc1 = nn.Linear(2*2*64,l1)\n",
    "        self.bn1 = nn.BatchNorm1d(l1)\n",
    "        #second layer : 250 to 100\n",
    "        self.fc2 = nn.Linear(l1,l2)  \n",
    "        self.bn2 = nn.BatchNorm1d(l2)\n",
    "        #outputs dim 10 so we can test the aux loss for classifying numbers\n",
    "        #use softmax on fc3?\n",
    "        self.fc3 = nn.Linear(l2,10)\n",
    "        self.dropout = nn.Dropout(drop)\n",
    "    def forward(self,x):\n",
    "        x = self.dropout(self.bn1(F.relu(self.fc1(x.view(-1,2*2*64)))))\n",
    "        x = self.dropout(self.bn2(F.relu(self.fc2(x))))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "class total_net_test(nn.Module):\n",
    "    def __init__(self,l1,l2,drop):\n",
    "        super(total_net_test,self).__init__()\n",
    "        self.convlayer = convlayer()\n",
    "        self.fclayer = shared_fclayer_test(l1,l2,drop)\n",
    "        self.final = final_predictionlayer()\n",
    "    def forward(self,x):\n",
    "        tmp1 = x.narrow(1,0,1) #viewing only one image\n",
    "        tmp2 = x.narrow(1,1,1) #viewing only one image\n",
    "        #applying the conv layers\n",
    "        tmp1 = self.convlayer.forward(tmp1) \n",
    "        tmp2 = self.convlayer.forward(tmp2)\n",
    "        #applying the fc layers\n",
    "        tmp1 = self.fclayer(tmp1)\n",
    "        tmp2 = self.fclayer(tmp2)\n",
    "        #viewing and final prediction\n",
    "        output = torch.cat((tmp1,tmp2),1)\n",
    "        output.view(-1,20)\n",
    "        x = F.softmax(self.final(output),dim=1)\n",
    "        return x\n",
    "\n",
    "class total_net_testrelu(nn.Module):\n",
    "    def __init__(self,l1,l2,drop):\n",
    "        super(total_net_testrelu,self).__init__()\n",
    "        self.convlayer = convlayer()\n",
    "        self.fclayer = shared_fclayer_test(l1,l2,drop)\n",
    "        self.final = final_predictionlayer()\n",
    "    def forward(self,x):\n",
    "        tmp1 = x.narrow(1,0,1) #viewing only one image\n",
    "        tmp2 = x.narrow(1,1,1) #viewing only one image\n",
    "        #applying the conv layers\n",
    "        tmp1 = self.convlayer.forward(tmp1) \n",
    "        tmp2 = self.convlayer.forward(tmp2)\n",
    "        #applying the fc layers\n",
    "        tmp1 = self.fclayer(tmp1)\n",
    "        tmp2 = self.fclayer(tmp2)\n",
    "        #viewing and final prediction\n",
    "        output = torch.cat((tmp1,tmp2),1)\n",
    "        output.view(-1,20)\n",
    "        x = F.relu(self.final(output))\n",
    "        return x\n",
    "\n",
    "class total_net_testnthg(nn.Module):\n",
    "    def __init__(self,l1,l2,drop):\n",
    "        super(total_net_testnthg,self).__init__()\n",
    "        self.convlayer = convlayer()\n",
    "        self.fclayer = shared_fclayer_test(l1,l2,drop)\n",
    "        self.final = final_predictionlayer()\n",
    "    def forward(self,x):\n",
    "        tmp1 = x.narrow(1,0,1) #viewing only one image\n",
    "        tmp2 = x.narrow(1,1,1) #viewing only one image\n",
    "        #applying the conv layers\n",
    "        tmp1 = self.convlayer.forward(tmp1) \n",
    "        tmp2 = self.convlayer.forward(tmp2)\n",
    "        #applying the fc layers\n",
    "        tmp1 = self.fclayer(tmp1)\n",
    "        tmp2 = self.fclayer(tmp2)\n",
    "        #viewing and final prediction\n",
    "        output = torch.cat((tmp1,tmp2),1)\n",
    "        output.view(-1,20)\n",
    "        x = self.final(output)\n",
    "        return x\n",
    "                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1 = 100, l2 =30, drop = 0.1\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.40% test_error 16.40% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.20% test_error 14.60% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.10% test_error 13.50% \n",
      "\n",
      "l1 = 100, l2 =30, drop = 0.25\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.60% test_error 14.30% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.70% test_error 14.30% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.00% test_error 13.50% \n",
      "\n",
      "l1 = 100, l2 =30, drop = 0.4\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.60% test_error 15.50% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.80% test_error 13.30% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 2.00% test_error 16.80% \n",
      "\n",
      "l1 = 100, l2 =50, drop = 0.1\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.50% test_error 13.40% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.60% test_error 15.20% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.00% test_error 14.10% \n",
      "\n",
      "l1 = 100, l2 =50, drop = 0.25\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.80% test_error 15.70% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.20% test_error 14.80% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.80% test_error 13.60% \n",
      "\n",
      "l1 = 100, l2 =50, drop = 0.4\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.50% test_error 14.70% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.40% test_error 17.80% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.00% test_error 12.70% \n",
      "\n",
      "l1 = 100, l2 =70, drop = 0.1\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.50% test_error 14.50% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.50% test_error 14.50% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.90% test_error 13.00% \n",
      "\n",
      "l1 = 100, l2 =70, drop = 0.25\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.00% test_error 14.80% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.50% test_error 13.40% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.60% test_error 13.20% \n",
      "\n",
      "l1 = 100, l2 =70, drop = 0.4\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.10% test_error 13.40% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.40% test_error 13.40% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.80% test_error 14.30% \n",
      "\n",
      "l1 = 100, l2 =100, drop = 0.1\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.10% test_error 14.20% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.60% test_error 13.50% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.70% test_error 13.30% \n",
      "\n",
      "l1 = 100, l2 =100, drop = 0.25\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.20% test_error 13.00% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.90% test_error 13.00% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.60% test_error 15.10% \n",
      "\n",
      "l1 = 100, l2 =100, drop = 0.4\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 3.40% test_error 15.70% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.80% test_error 13.80% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.20% test_error 14.20% \n",
      "\n",
      "l1 = 100, l2 =150, drop = 0.1\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.00% test_error 14.20% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.50% test_error 12.40% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.80% test_error 13.20% \n",
      "\n",
      "l1 = 100, l2 =150, drop = 0.25\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.00% test_error 13.20% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.70% test_error 15.40% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.90% test_error 13.00% \n",
      "\n",
      "l1 = 100, l2 =150, drop = 0.4\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.10% test_error 13.60% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.20% test_error 14.40% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.60% test_error 14.70% \n",
      "\n",
      "l1 = 100, l2 =200, drop = 0.1\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.70% test_error 12.40% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.30% test_error 14.60% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.30% test_error 14.00% \n",
      "\n",
      "l1 = 100, l2 =200, drop = 0.25\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.00% test_error 14.30% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.70% test_error 15.40% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.90% test_error 13.80% \n",
      "\n",
      "l1 = 100, l2 =200, drop = 0.4\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 2.00% test_error 13.90% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.70% test_error 14.80% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.80% test_error 13.10% \n",
      "\n",
      "l1 = 150, l2 =30, drop = 0.1\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.40% test_error 15.60% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.70% test_error 13.90% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.30% test_error 14.70% \n",
      "\n",
      "l1 = 150, l2 =30, drop = 0.25\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.40% test_error 12.70% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.40% test_error 15.20% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.40% test_error 13.70% \n",
      "\n",
      "l1 = 150, l2 =30, drop = 0.4\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.30% test_error 16.10% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.50% test_error 14.80% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.50% test_error 12.90% \n",
      "\n",
      "l1 = 150, l2 =50, drop = 0.1\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.40% test_error 13.80% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.60% test_error 14.00% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.50% test_error 12.50% \n",
      "\n",
      "l1 = 150, l2 =50, drop = 0.25\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.30% test_error 13.40% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.60% test_error 14.50% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.90% test_error 14.30% \n",
      "\n",
      "l1 = 150, l2 =50, drop = 0.4\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.70% test_error 17.40% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.40% test_error 15.00% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.70% test_error 14.40% \n",
      "\n",
      "l1 = 150, l2 =70, drop = 0.1\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.90% test_error 15.00% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.40% test_error 13.00% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.60% test_error 13.10% \n",
      "\n",
      "l1 = 150, l2 =70, drop = 0.25\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.60% test_error 12.20% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.50% test_error 13.40% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.90% test_error 13.00% \n",
      "\n",
      "l1 = 150, l2 =70, drop = 0.4\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.90% test_error 15.90% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.40% test_error 14.00% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.80% test_error 13.90% \n",
      "\n",
      "l1 = 150, l2 =100, drop = 0.1\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.30% test_error 12.00% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.70% test_error 13.40% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.20% test_error 11.90% \n",
      "\n",
      "l1 = 150, l2 =100, drop = 0.25\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.70% test_error 11.50% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.20% test_error 14.60% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.70% test_error 13.90% \n",
      "\n",
      "l1 = 150, l2 =100, drop = 0.4\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.50% test_error 14.00% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.70% test_error 13.50% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.30% test_error 13.60% \n",
      "\n",
      "l1 = 150, l2 =150, drop = 0.1\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.50% test_error 13.60% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.40% test_error 12.70% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.90% test_error 13.10% \n",
      "\n",
      "l1 = 150, l2 =150, drop = 0.25\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.20% test_error 12.60% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.10% test_error 12.00% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.20% test_error 13.90% \n",
      "\n",
      "l1 = 150, l2 =150, drop = 0.4\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.00% test_error 13.90% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.70% test_error 14.30% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.90% test_error 15.20% \n",
      "\n",
      "l1 = 150, l2 =200, drop = 0.1\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 16.20% test_error 26.90% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.70% test_error 14.70% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 2.50% test_error 14.90% \n",
      "\n",
      "l1 = 150, l2 =200, drop = 0.25\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.00% test_error 12.50% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 2.20% test_error 14.20% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.80% test_error 12.80% \n",
      "\n",
      "l1 = 150, l2 =200, drop = 0.4\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.40% test_error 15.30% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 2.40% test_error 16.60% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.80% test_error 13.30% \n",
      "\n",
      "l1 = 200, l2 =30, drop = 0.1\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.20% test_error 12.50% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.50% test_error 13.30% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.50% test_error 13.70% \n",
      "\n",
      "l1 = 200, l2 =30, drop = 0.25\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.90% test_error 16.10% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.90% test_error 15.40% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.70% test_error 14.30% \n",
      "\n",
      "l1 = 200, l2 =30, drop = 0.4\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 28.30% test_error 35.10% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.40% test_error 13.40% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.70% test_error 14.20% \n",
      "\n",
      "l1 = 200, l2 =50, drop = 0.1\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.00% test_error 13.40% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.60% test_error 15.20% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.40% test_error 13.50% \n",
      "\n",
      "l1 = 200, l2 =50, drop = 0.25\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.40% test_error 13.40% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.30% test_error 14.50% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.40% test_error 13.50% \n",
      "\n",
      "l1 = 200, l2 =50, drop = 0.4\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.30% test_error 16.10% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.60% test_error 13.90% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.80% test_error 13.40% \n",
      "\n",
      "l1 = 200, l2 =70, drop = 0.1\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.70% test_error 14.10% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.90% test_error 15.30% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.50% test_error 11.50% \n",
      "\n",
      "l1 = 200, l2 =70, drop = 0.25\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.40% test_error 14.40% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.00% test_error 14.30% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.80% test_error 13.70% \n",
      "\n",
      "l1 = 200, l2 =70, drop = 0.4\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.70% test_error 14.30% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.10% test_error 13.60% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.40% test_error 12.80% \n",
      "\n",
      "l1 = 200, l2 =100, drop = 0.1\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.80% test_error 13.00% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.00% test_error 14.80% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.80% test_error 12.10% \n",
      "\n",
      "l1 = 200, l2 =100, drop = 0.25\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.70% test_error 13.20% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.80% test_error 12.40% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.70% test_error 13.40% \n",
      "\n",
      "l1 = 200, l2 =100, drop = 0.4\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.00% test_error 14.00% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.10% test_error 14.60% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.80% test_error 14.50% \n",
      "\n",
      "l1 = 200, l2 =150, drop = 0.1\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.00% test_error 12.00% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.90% test_error 14.50% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.70% test_error 14.50% \n",
      "\n",
      "l1 = 200, l2 =150, drop = 0.25\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.90% test_error 12.00% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.70% test_error 13.80% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.10% test_error 13.70% \n",
      "\n",
      "l1 = 200, l2 =150, drop = 0.4\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.10% test_error 13.60% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.80% test_error 13.00% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.30% test_error 13.00% \n",
      "\n",
      "l1 = 200, l2 =200, drop = 0.1\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.80% test_error 12.30% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.90% test_error 14.60% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.90% test_error 11.90% \n",
      "\n",
      "l1 = 200, l2 =200, drop = 0.25\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.30% test_error 11.20% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.60% test_error 13.30% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.50% test_error 12.00% \n",
      "\n",
      "l1 = 200, l2 =200, drop = 0.4\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 2.60% test_error 14.10% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.90% test_error 13.30% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.80% test_error 13.80% \n",
      "\n",
      "l1 = 264, l2 =30, drop = 0.1\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.50% test_error 15.90% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.30% test_error 15.40% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.80% test_error 15.00% \n",
      "\n",
      "l1 = 264, l2 =30, drop = 0.25\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.30% test_error 13.70% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.00% test_error 13.00% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.30% test_error 13.80% \n",
      "\n",
      "l1 = 264, l2 =30, drop = 0.4\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.60% test_error 14.40% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.90% test_error 14.10% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.00% test_error 14.60% \n",
      "\n",
      "l1 = 264, l2 =50, drop = 0.1\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.10% test_error 13.00% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.30% test_error 12.90% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.70% test_error 14.40% \n",
      "\n",
      "l1 = 264, l2 =50, drop = 0.25\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.20% test_error 12.00% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.70% test_error 13.60% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.80% test_error 15.50% \n",
      "\n",
      "l1 = 264, l2 =50, drop = 0.4\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.00% test_error 14.70% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.60% test_error 15.00% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.90% test_error 15.10% \n",
      "\n",
      "l1 = 264, l2 =70, drop = 0.1\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.50% test_error 13.10% \n",
      "\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n"
     ]
    }
   ],
   "source": [
    "goodLayers = []\n",
    "nb_epochs = 50\n",
    "eta = 9e-2\n",
    "bn = 25\n",
    "for l1 in [100,150,200,264,350]:\n",
    "    for l2 in [30,50,70,100,150,200]:\n",
    "        for drop in [0.1,0.25,0.4]:\n",
    "            err = 0;\n",
    "            print(\"l1 = {}, l2 ={}, drop = {}\".format(l1,l2,drop))\n",
    "            for n in range(3):\n",
    "                model = total_net_test(l1,l2,drop)\n",
    "                err += run_net(model,train_input,train_target,\n",
    "                               test_input,test_target,nb_epochs,eta,bn)\n",
    "                \n",
    "            if err/3 <= 14:\n",
    "                goodList.append([err/3,l1,l2,drop])\n",
    "print(goodList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13.066666666666668, 25, 0.1, 25], [13.299999999999999, 25, 0.1, 100], [13.866666666666667, 25, 0.075, 25], [13.6, 25, 0.05, 100], [13.799999999999999, 25, 0.033, 100], [12.733333333333334, 37, 0.1, 25], [13.366666666666665, 37, 0.075, 25], [13.733333333333334, 37, 0.033, 25], [12.233333333333334, 50, 0.1, 25], [13.466666666666667, 50, 0.1, 50], [12.866666666666667, 50, 0.05, 25], [14.0, 100, 70, 0.1], [13.799999999999999, 100, 70, 0.25], [13.700000000000001, 100, 70, 0.4], [13.666666666666666, 100, 100, 0.1], [13.700000000000001, 100, 100, 0.25], [13.266666666666667, 100, 150, 0.1], [13.866666666666667, 100, 150, 0.25], [13.666666666666666, 100, 200, 0.1], [13.933333333333335, 100, 200, 0.4], [13.866666666666667, 150, 30, 0.25], [13.433333333333335, 150, 50, 0.1], [13.700000000000001, 150, 70, 0.1], [12.866666666666667, 150, 70, 0.25], [12.433333333333332, 150, 100, 0.1], [13.333333333333334, 150, 100, 0.25], [13.700000000000001, 150, 100, 0.4], [13.133333333333335, 150, 150, 0.1], [12.833333333333334, 150, 150, 0.25], [13.166666666666666, 150, 200, 0.25], [13.166666666666666, 200, 30, 0.1], [13.799999999999999, 200, 50, 0.25], [13.633333333333333, 200, 70, 0.1], [13.566666666666668, 200, 70, 0.4], [13.299999999999999, 200, 100, 0.1], [13.0, 200, 100, 0.25], [13.666666666666666, 200, 150, 0.1], [13.166666666666666, 200, 150, 0.25], [13.200000000000001, 200, 150, 0.4], [12.933333333333332, 200, 200, 0.1], [12.166666666666666, 200, 200, 0.25], [13.733333333333334, 200, 200, 0.4], [13.5, 264, 30, 0.25], [13.433333333333332, 264, 50, 0.1], [13.700000000000001, 264, 50, 0.25], [13.633333333333335, 264, 70, 0.1], [13.433333333333335, 264, 70, 0.25], [13.333333333333334, 264, 100, 0.1], [11.566666666666668, 264, 100, 0.25], [13.833333333333334, 264, 100, 0.4], [13.166666666666666, 264, 150, 0.1], [13.933333333333332, 264, 150, 0.25]]\n"
     ]
    }
   ],
   "source": [
    "print(goodList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model tested : total_net_testnthg\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.80% test_error 13.20% \n",
      "\n",
      "Model tested : total_net_testnthg\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.70% test_error 14.50% \n",
      "\n",
      "Model tested : total_net_testnthg\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.70% test_error 15.30% \n",
      "\n",
      "total_net_testnthg(\n",
      "  (convlayer): convlayer(\n",
      "    (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  )\n",
      "  (fclayer): shared_fclayer_test(\n",
      "    (fc1): Linear(in_features=256, out_features=264, bias=True)\n",
      "    (bn1): BatchNorm1d(264, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (fc2): Linear(in_features=264, out_features=100, bias=True)\n",
      "    (bn2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (fc3): Linear(in_features=100, out_features=10, bias=True)\n",
      "    (dropout): Dropout(p=0.25, inplace=False)\n",
      "  )\n",
      "  (final): final_predictionlayer(\n",
      "    (final): Linear(in_features=20, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "14.333333333333334\n",
      "Model tested : total_net_testrelu\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.80% test_error 13.40% \n",
      "\n",
      "Model tested : total_net_testrelu\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.60% test_error 14.40% \n",
      "\n",
      "Model tested : total_net_testrelu\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.60% test_error 14.10% \n",
      "\n",
      "total_net_testrelu(\n",
      "  (convlayer): convlayer(\n",
      "    (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  )\n",
      "  (fclayer): shared_fclayer_test(\n",
      "    (fc1): Linear(in_features=256, out_features=264, bias=True)\n",
      "    (bn1): BatchNorm1d(264, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (fc2): Linear(in_features=264, out_features=100, bias=True)\n",
      "    (bn2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (fc3): Linear(in_features=100, out_features=10, bias=True)\n",
      "    (dropout): Dropout(p=0.25, inplace=False)\n",
      "  )\n",
      "  (final): final_predictionlayer(\n",
      "    (final): Linear(in_features=20, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "13.966666666666663\n",
      "Model tested : total_net_test\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.20% test_error 15.50% \n",
      "\n",
      "Model tested : total_net_test\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.00% test_error 16.50% \n",
      "\n",
      "Model tested : total_net_test\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.10% test_error 15.80% \n",
      "\n",
      "total_net_test(\n",
      "  (convlayer): convlayer(\n",
      "    (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  )\n",
      "  (fclayer): shared_fclayer_test(\n",
      "    (fc1): Linear(in_features=256, out_features=264, bias=True)\n",
      "    (bn1): BatchNorm1d(264, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (fc2): Linear(in_features=264, out_features=100, bias=True)\n",
      "    (bn2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (fc3): Linear(in_features=100, out_features=10, bias=True)\n",
      "    (dropout): Dropout(p=0.25, inplace=False)\n",
      "  )\n",
      "  (final): final_predictionlayer(\n",
      "    (final): Linear(in_features=20, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "15.933333333333332\n"
     ]
    }
   ],
   "source": [
    "#With the best layer sizes, try diff activations\n",
    "nb_epochs = 50\n",
    "eta = 9e-2\n",
    "bn = 25\n",
    "l1,l2,drop = 264,100,0.25\n",
    "for model in [total_net_testnthg(l1,l2,drop),total_net_testrelu(l1,l2,drop),total_net_test(l1,l2,drop)]:\n",
    "    err =0;\n",
    "    for n in range(3):\n",
    "        err+=run_net(model,train_input,train_target,test_input,test_target,\n",
    "               nb_epochs,eta,bn)\n",
    "    print(model)\n",
    "    print(err/3)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
