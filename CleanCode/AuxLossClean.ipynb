{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaned up basic LeNet exploration.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### *Starting points : Importing, getting data, normalizing*\n",
    "`Stuff you need, but is hidden here.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using : cuda\n"
     ]
    }
   ],
   "source": [
    "#Starting points : import everything, use cuda if available\n",
    "import torch\n",
    "import math\n",
    "from torch.nn import functional as F\n",
    "import dlc_practical_prologue as prologue\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from torch import optim\n",
    "from torch import Tensor\n",
    "from torch import nn\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(\"Using : {}\".format(device))\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"Using : {}\".format(device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_(train_input,test_input):\n",
    "    \"\"\"Function to normalize the input --> done IN PLACE!\"\"\"\n",
    "    mu, std = train_input.mean(), train_input.std()\n",
    "    train_inputOut = train_input.sub_(mu).div_(std)\n",
    "    test_inputOut = test_input.sub_(mu).div_(std)\n",
    "    return train_inputOut, test_inputOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating pairs of 14x14 and sending to device. Here default\n",
    "N=1000\n",
    "(train_input,train_target,train_classes, \\\n",
    " test_input,test_target,test_classes) = prologue.generate_pair_sets(N)\n",
    "train_input = train_input.to(device)\n",
    "test_input = test_input.to(device)\n",
    "train_target = train_target.to(device)\n",
    "test_target = test_target.to(device)\n",
    "train_classes, test_classes = train_classes.to(device), test_classes.to(device)\n",
    "train_input,test_input = norm_(train_input,test_input);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model : Shared-weight ConvNet. Same as Plain ConvNet but just separating the inputs.\n",
    "\n",
    "`Conv layer 1 : takes 1x14x14 --> 32x12x12 --> Maxpool --> 32x6x6` \n",
    "\n",
    "`Conv Layer 2 : Takes 32x6x6 --> 64x4x4 --> Maxpool 64x2x2`\n",
    "\n",
    "`FC 1 : View(-1,64*2*2) --> 264 (random number but works)`\n",
    "\n",
    "`FC 2 : 264-->100 --> FC3 --> 2`\n",
    "\n",
    "`Using dropout, batchnorm on all hidden layers (FC1, FC2)`\n",
    "\n",
    "`Softmax as last activation, ReLU for all the others`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Conv layers, based on the filter size and layer sizes tested in explorationLeNetDual\n",
    "# must take 1x14x14 (so the same layers is used on both images)\n",
    "# Separated the modules because I couldn't figure out how to make a single net work...\n",
    "# will maybe merge into a single net later.\n",
    "class convlayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(convlayer, self).__init__()\n",
    "        #self.conv1 : takes 1x14x14, gives 32x12x12, then maxpool(k=2) -> 32x6x6\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3) \n",
    "        #self.conv2 : takes 32x6x6, gives 64x4x4, then maxpool(k=2) -> outputs 64x2x2 to the fc layers\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), kernel_size=2,stride=2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), kernel_size=2,stride=2))\n",
    "        return x\n",
    "#fc layers, adding a supp layer that has output dim 10 (instead of 2)\n",
    "#in order to maybe calculate an aux loss on this output to have classification?\n",
    "# REMEMBER TO ADD AN ACTIVATION WHEN CALLING SHARED_FCLAYER IN YOUR NETWORK!!\n",
    "# ex : F.relu(self.shared_fclayer(tmp1) or F.softmax(...,dim=1)\n",
    "class shared_fclayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(shared_fclayer,self).__init__()\n",
    "        #gets in 64x2x2, convers to 1x250\n",
    "        self.fc1 = nn.Linear(2*2*64,264)\n",
    "        self.bn1 = nn.BatchNorm1d(264)\n",
    "        #second layer : 250 to 100\n",
    "        self.fc2 = nn.Linear(264,100)  \n",
    "        self.bn2 = nn.BatchNorm1d(100)\n",
    "        #outputs dim 10 so we can test the aux loss for classifying numbers\n",
    "        #use softmax on fc3?\n",
    "        self.fc3 = nn.Linear(100,10)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "    def forward(self,x):\n",
    "        x = self.dropout(self.bn1(F.relu(self.fc1(x.view(-1,2*2*64)))))\n",
    "        x = self.dropout(self.bn2(F.relu(self.fc2(x))))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "#extra final layer, not shared\n",
    "class final_predictionlayer(nn.Module):\n",
    "    #this final layer should take 2*10 (one for each image) and output 2 \n",
    "    def __init__(self):\n",
    "        super(final_predictionlayer,self).__init__()\n",
    "        self.final = nn.Linear(20,2)\n",
    "    def forward(self,x):\n",
    "        x = F.softmax(self.final(x),dim=1)\n",
    "        return x\n",
    "\n",
    "#weight-sharing Net\n",
    "#returns tmp1, tmp2 in order to calculate and optimize with auxLoss\n",
    "#Those will be compared to the train_classes.narrow(1,0,1) and .narrow(1,1,1)\n",
    "\n",
    "class AuxLossWS_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AuxLossWS_Net,self).__init__()\n",
    "        self.convlayer = convlayer()\n",
    "        self.fclayer = shared_fclayer()\n",
    "        self.final = final_predictionlayer()\n",
    "    def forward(self,x):\n",
    "        tmp1 = x.narrow(1,0,1) #viewing only one image\n",
    "        tmp2 = x.narrow(1,1,1) #viewing only one image\n",
    "        #applying the conv layers\n",
    "        tmp1 = self.convlayer.forward(tmp1) \n",
    "        tmp2 = self.convlayer.forward(tmp2)\n",
    "        #applying the fc layers\n",
    "        tmp1 = F.softmax(self.fclayer(tmp1),dim=1)\n",
    "        tmp2 = F.softmax(self.fclayer(tmp2),dim=1)\n",
    "        #viewing and final prediction\n",
    "        output = torch.cat((tmp1,tmp2),1)\n",
    "        output.view(-1,20)\n",
    "        x = self.final(output)\n",
    "        return x, tmp1, tmp2     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train_model, compute_nb_errors, run_net\n",
    "\n",
    "##### *Adapted to also train for auxLoss. Gamma determines the \"weight\" of the primary loss. Works best with gamma = 0.67, maybe try other values.*\n",
    "*run_net(...) does everything, use only this function, it will call the others. (See params)*\n",
    "\n",
    "*run_net(...) **RETURNS** the test error as a float, useful for average over multiple runs* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_aux(model, train_input, train_target, train_classes, nb_epochs=50, \n",
    "                eta=9e-2, mini_batch_size=25, \n",
    "                    alpha=.75, gamma=1,\n",
    "                    printTrain = False, graphLoss = False):\n",
    "    \"\"\"Trains the model, using CrossEntropyLoss and SGD \n",
    "    Model : Architecture to be tested, pytorch.nn.Module\n",
    "    Train_input : Input tensors Nx2x14x14, N = 1000\n",
    "    Train_target : Target labels, N, classes = 0 or 1\n",
    "    Nb_epochs : nb of epochs to train over\n",
    "    eta : Learning rate\n",
    "    mini_batch_size : Size of minibatch to be processed\"\"\"\n",
    "    \n",
    "    #Squeeze the classes labels (hotlabeling) for the auxLoss\n",
    "    trainlabel_1 = (train_classes.narrow(1,0,1)).squeeze()\n",
    "    trainlabel_2 = (train_classes.narrow(1,1,1)).squeeze()\n",
    "\n",
    "    model.train(True)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model.to(device)\n",
    "    criterion.to(device)\n",
    "    optimizer = optim.SGD(model.parameters(),lr=eta)\n",
    "    losses = []\n",
    "    for e in range(nb_epochs):\n",
    "        for b in range(0, train_input.size(0), mini_batch_size):    \n",
    "            \n",
    "            out_compare, out_1, out_2 = model(train_input.narrow(0, b, mini_batch_size))\n",
    "            #Main Loss\n",
    "            loss_compare = criterion(out_compare, train_target.narrow(0, b, mini_batch_size))\n",
    "            #AuxLoss\n",
    "            loss_1 = criterion(out_1, trainlabel_1.narrow(0, b, mini_batch_size))\n",
    "            loss_2 = criterion(out_2, trainlabel_2.narrow(0, b, mini_batch_size))\n",
    "            #Weighted sum. Used to be Alpha*Loss1 + Beta*Loss2 + Gamma* Loss compare\n",
    "            #Didn't work well, try again with other alpha/betas < 1.\n",
    "            loss_sum = alpha*loss_1 + alpha*loss_2 + gamma*loss_compare\n",
    "            \n",
    "            losses.append(loss_sum)\n",
    "            model.zero_grad()\n",
    "            loss_sum.backward()\n",
    "            optimizer.step()\n",
    "        if printTrain : \n",
    "            print(\"Epoch : {} :: Train error : {}/{}, {:0f}%\".format(e,\n",
    "            compute_nb_errors(model,train_input,train_target,mini_batch_size),train_target.size(0),\n",
    "            (100*compute_nb_errors(model,train_input,train_target,mini_batch_size)/train_target.size(0))))\n",
    "    if graphLoss : \n",
    "        plt.plot(losses)\n",
    "        plt.ylabel('loss')\n",
    "#--------------------------------------------------------------------------------------------------------#\n",
    "def compute_nb_errors(model,data_input,data_target,mini_batch_size):\n",
    "    \"\"\"std from the sÃ©ries\"\"\"\n",
    "    nb_errors = 0;\n",
    "    model.to(device)\n",
    "    data_input, data_target = data_input.to(device),data_target.to(device)\n",
    "    for b in range(0,data_input.size(0),mini_batch_size):\n",
    "        output, _, _ = model(data_input.narrow(0,b,mini_batch_size))\n",
    "        _, predicted_classes = torch.max(output, 1)\n",
    "        for k in range(mini_batch_size):\n",
    "            if data_target[b+k]!=predicted_classes[k]:\n",
    "                nb_errors += 1\n",
    "    \n",
    "    return nb_errors\n",
    "#--------------------------------------------------------------------------------------------------------#\n",
    "def run_net_aux(model,train_input,train_target, train_classes,\n",
    "            test_input, test_target, test_classes,\n",
    "            nb_epochs = 50,eta=9e-2,mini_batch_size=25,\n",
    "            alpha = .75, gamma=1,\n",
    "            printTrain = False,graphLoss = False):\n",
    "    \"\"\"\"\"\"\n",
    "    model.to(device)\n",
    "    print(\"Model tested : {}\".format(str(model)[:str(model).find('(')]))\n",
    "    print(\"\"\"Using {} epochs, lr = {:.04f},Mini batch size = {}\"\"\".format(nb_epochs,\n",
    "                                                                          eta,mini_batch_size))\n",
    "    train_model_aux(model, train_input, train_target, train_classes,\n",
    "                nb_epochs, eta, mini_batch_size, \n",
    "                    alpha, gamma, printTrain,graphLoss)\n",
    "    model.train(False)\n",
    "    train_error = compute_nb_errors(model, train_input, train_target,mini_batch_size) / train_input.size(0) * 100\n",
    "    test_error = compute_nb_errors(model, test_input, test_target,mini_batch_size) / test_input.size(0) * 100\n",
    "    print('train_error {:.02f}% test_error {:.02f}% \\n'.format(\n",
    "                train_error,\n",
    "                test_error\n",
    "            )\n",
    "        )\n",
    "    return float(test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 2.30% test_error 4.50% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.60% test_error 4.60% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.50% test_error 4.30% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.50% test_error 4.90% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.60% test_error 3.80% \n",
      "\n",
      "Softmax Net : Softmax only on tmp1, tmp2 NO RELU AT ALL ON FC3\n",
      "Average error for gamma = 0.67, over 5 runs :: 4.420000\n"
     ]
    }
   ],
   "source": [
    "err = 0.0;\n",
    "nb = 5\n",
    "gamma = 0.67\n",
    "#Testing with softmax on fully_connected (on linear(100,10)) on TMP1,2\n",
    "for n in range(nb):\n",
    "    err += run_net_aux(AuxLossWS_Net(), train_input, train_target, train_classes,\n",
    "                test_input, test_target, test_classes,\n",
    "                       alpha = 1, gamma = gamma)\n",
    "print(\"Softmax Net : Softmax only on tmp1, tmp2 NO RELU AT ALL ON FC3\")\n",
    "print(\"Average error for gamma = {}, over {} runs :: {:02f}\".format(gamma,nb,err/nb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.10% test_error 3.70% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.50% test_error 3.60% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.50% test_error 4.20% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.80% test_error 3.40% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.40% test_error 4.50% \n",
      "\n",
      "Softmax Net : Softmax only on tmp1, tmp2 NO RELU AT ALL ON FC3\n",
      "Average error for gamma = 0.8, over 5 runs :: 3.880000\n"
     ]
    }
   ],
   "source": [
    "err = 0.0;\n",
    "nb = 5\n",
    "\n",
    "#Testing with softmax on fully_connected (on linear(100,10)) on TMP1,2\n",
    "for n in range(nb):\n",
    "    err += run_net_aux(AuxLossWS_Net(), train_input, train_target, train_classes,\n",
    "                test_input, test_target, test_classes,\n",
    "                       alpha=1,gamma = 1)\n",
    "print(\"AuxLossWS_Net\")\n",
    "print(\"Average error for gamma = {}, over {} runs :: {:02f}\".format(gamma,nb,err/nb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AuxLossWS_Net\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 5.60% test_error 8.30% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 8.00% test_error 7.50% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 5.30% test_error 5.70% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 3.00% test_error 5.30% \n",
      "\n",
      "Average error for alpha = 0.25, gamma = 0.25, over 4 runs :: 6.700000\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 2.40% test_error 5.30% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 2.30% test_error 4.80% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 2.80% test_error 6.50% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 2.40% test_error 5.90% \n",
      "\n",
      "Average error for alpha = 0.25, gamma = 0.5, over 4 runs :: 5.625000\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 2.00% test_error 5.60% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.20% test_error 5.60% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.40% test_error 5.50% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 2.00% test_error 5.10% \n",
      "\n",
      "Average error for alpha = 0.25, gamma = 0.75, over 4 runs :: 5.450000\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.20% test_error 5.20% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 2.40% test_error 9.60% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.00% test_error 5.20% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 3.10% test_error 6.50% \n",
      "\n",
      "Average error for alpha = 0.25, gamma = 1, over 4 runs :: 6.625000\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 5.40% test_error 6.40% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 5.80% test_error 6.30% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 3.50% test_error 7.00% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 5.90% test_error 7.40% \n",
      "\n",
      "Average error for alpha = 0.5, gamma = 0.25, over 4 runs :: 6.775000\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 2.40% test_error 5.00% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 2.30% test_error 4.70% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.50% test_error 4.70% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 2.20% test_error 5.70% \n",
      "\n",
      "Average error for alpha = 0.5, gamma = 0.5, over 4 runs :: 5.025000\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.90% test_error 4.00% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 2.20% test_error 4.80% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.30% test_error 4.40% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.70% test_error 4.00% \n",
      "\n",
      "Average error for alpha = 0.5, gamma = 0.75, over 4 runs :: 4.300000\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.10% test_error 3.00% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.60% test_error 3.30% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.80% test_error 3.60% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.50% test_error 5.50% \n",
      "\n",
      "Average error for alpha = 0.5, gamma = 1, over 4 runs :: 3.850000\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 4.10% test_error 6.10% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 5.90% test_error 8.90% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.30% test_error 5.10% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 8.00% test_error 8.40% \n",
      "\n",
      "Average error for alpha = 0.75, gamma = 0.25, over 4 runs :: 7.125000\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 2.30% test_error 4.70% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 2.20% test_error 5.40% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 2.20% test_error 4.90% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 2.20% test_error 4.90% \n",
      "\n",
      "Average error for alpha = 0.75, gamma = 0.5, over 4 runs :: 4.975000\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.40% test_error 5.00% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 2.30% test_error 5.00% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 2.40% test_error 4.10% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 2.40% test_error 4.80% \n",
      "\n",
      "Average error for alpha = 0.75, gamma = 0.75, over 4 runs :: 4.725000\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.10% test_error 2.30% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n"
     ]
    }
   ],
   "source": [
    "nb = 4\n",
    "print(\"AuxLossWS_Net\")\n",
    "arrayValues = []\n",
    "#Testing with softmax on fully_connected (on linear(100,10)) on TMP1,2\n",
    "for a in [0.25,0.5,0.75]:\n",
    "    for c in [0.25,0.5,0.75,1]:\n",
    "        err = 0.0;\n",
    "        for n in range(nb):\n",
    "            err += run_net_aux(AuxLossWS_Net(), train_input, train_target, train_classes,\n",
    "                            test_input, test_target, test_classes,\n",
    "                                   alpha=a,gamma = c)\n",
    "        print(\"Average error for alpha = {}, gamma = {}, over {} runs :: {:02f}\".format(a,c,nb,err/nb))\n",
    "        err = err/nb;\n",
    "        arrayValues.append([err,a,c])\n",
    "print(arrayValues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.7, 0.25, 0.25], [5.625, 0.25, 0.5], [5.450000000000001, 0.25, 0.75], [6.625, 0.25, 1], [6.7749999999999995, 0.5, 0.25], [5.0249999999999995, 0.5, 0.5], [4.3, 0.5, 0.75], [3.85, 0.5, 1], [7.125, 0.75, 0.25], [4.9750000000000005, 0.75, 0.5], [4.7250000000000005, 0.75, 0.75], [3.775, 0.75, 1]]\n"
     ]
    }
   ],
   "source": [
    "print(arrayValues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 4.30% test_error 6.50% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 4.50% test_error 5.60% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 4.00% test_error 6.00% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 3.00% test_error 5.20% \n",
      "\n",
      "Average error for alpha = 1, gamma = 0.25, over 4 runs :: 5.825000\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 2.20% test_error 4.80% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 2.30% test_error 4.80% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 2.20% test_error 5.00% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 2.40% test_error 5.00% \n",
      "\n",
      "Average error for alpha = 1, gamma = 0.5, over 4 runs :: 4.900000\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.50% test_error 4.30% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 2.30% test_error 4.60% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 2.10% test_error 4.40% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.30% test_error 4.90% \n",
      "\n",
      "Average error for alpha = 1, gamma = 0.75, over 4 runs :: 4.550000\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.80% test_error 3.20% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.60% test_error 3.80% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.10% test_error 4.50% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.90% test_error 3.70% \n",
      "\n",
      "Average error for alpha = 1, gamma = 1, over 4 runs :: 3.800000\n",
      "[[6.7, 0.25, 0.25], [5.625, 0.25, 0.5], [5.450000000000001, 0.25, 0.75], [6.625, 0.25, 1], [6.7749999999999995, 0.5, 0.25], [5.0249999999999995, 0.5, 0.5], [4.3, 0.5, 0.75], [3.85, 0.5, 1], [7.125, 0.75, 0.25], [4.9750000000000005, 0.75, 0.5], [4.7250000000000005, 0.75, 0.75], [3.775, 0.75, 1], [5.825, 1, 0.25], [4.9, 1, 0.5], [4.549999999999999, 1, 0.75], [3.8, 1, 1]]\n"
     ]
    }
   ],
   "source": [
    "for a in [1]:\n",
    "    for c in [0.25,0.5,0.75,1]:\n",
    "        err = 0.0;\n",
    "        for n in range(nb):\n",
    "            err += run_net_aux(AuxLossWS_Net(), train_input, train_target, train_classes,\n",
    "                            test_input, test_target, test_classes,\n",
    "                                   alpha=a,gamma = c)\n",
    "        print(\"Average error for alpha = {}, gamma = {}, over {} runs :: {:02f}\".format(a,c,nb,err/nb))\n",
    "        err = err/nb;\n",
    "        arrayValues.append([err,a,c])\n",
    "print(arrayValues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALPHA = 0.5\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.60% test_error 4.70% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.80% test_error 3.40% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.70% test_error 4.30% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.70% test_error 4.20% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.90% test_error 4.40% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.80% test_error 4.00% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.60% test_error 3.80% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.50% test_error 5.10% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.60% test_error 3.80% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.70% test_error 4.10% \n",
      "\n",
      "ALPHA = 0.67\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.70% test_error 4.30% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.90% test_error 3.90% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.80% test_error 4.00% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.40% test_error 4.20% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.60% test_error 3.90% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.80% test_error 3.90% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 2.20% test_error 5.00% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.70% test_error 3.50% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.90% test_error 3.40% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.50% test_error 4.30% \n",
      "\n",
      "ALPHA = 0.75\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.90% test_error 4.10% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.90% test_error 3.50% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.90% test_error 3.60% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.00% test_error 3.70% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.70% test_error 3.50% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.60% test_error 4.30% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.80% test_error 3.40% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.90% test_error 3.70% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.60% test_error 3.50% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.80% test_error 3.10% \n",
      "\n",
      "ALPHA = 1\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.80% test_error 3.80% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.80% test_error 3.10% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.50% test_error 3.40% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.40% test_error 4.40% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.90% test_error 3.60% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.60% test_error 4.20% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.00% test_error 3.90% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.50% test_error 3.60% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 0.90% test_error 3.20% \n",
      "\n",
      "Model tested : AuxLossWS_Net\n",
      "Using 50 epochs, lr = 0.0900,Mini batch size = 25\n",
      "train_error 1.60% test_error 3.50% \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Run 10 times : Get accuracy. Then get mean and Std, for gamma = 1, and a in 0.5, 0.67, 0.75, 1 (rows 0 to 3)\n",
    "x = torch.zeros(4,10,dtype =torch.float64,device='cuda')\n",
    "i=0;\n",
    "for a in [0.5,0.67,0.75,1]:\n",
    "    print(\"ALPHA = {}\".format(a))\n",
    "    for j in range(10):\n",
    "        x[i,j]=run_net_aux(AuxLossWS_Net(), train_input, train_target, train_classes,\n",
    "                            test_input, test_target, test_classes,\n",
    "                                   alpha=a,gamma = 1)\n",
    "    i+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.7000, 3.4000, 4.3000, 4.2000, 4.4000, 4.0000, 3.8000, 5.1000, 3.8000,\n",
      "         4.1000],\n",
      "        [4.3000, 3.9000, 4.0000, 4.2000, 3.9000, 3.9000, 5.0000, 3.5000, 3.4000,\n",
      "         4.3000],\n",
      "        [4.1000, 3.5000, 3.6000, 3.7000, 3.5000, 4.3000, 3.4000, 3.7000, 3.5000,\n",
      "         3.1000],\n",
      "        [3.8000, 3.1000, 3.4000, 4.4000, 3.6000, 4.2000, 3.9000, 3.6000, 3.2000,\n",
      "         3.5000]], device='cuda:0', dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "\n",
    "mu = x.mean(1)\n",
    "std = x.std(1)\n",
    "alpha = torch.Tensor([0.5,0.67,0.75,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy :  tensor([4.1800, 4.0400, 3.6400, 3.6700], device='cuda:0', dtype=torch.float64) \n",
      " Accuracy Std Dev :  tensor([0.4849, 0.4526, 0.3438, 0.4138], device='cuda:0', dtype=torch.float64) \n",
      " for Alpha = tensor([0.5000, 0.6700, 0.7500, 1.0000])\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean accuracy : \",mu, \"\\n Accuracy Std Dev : \",std, \"\\n for Alpha =\",alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
